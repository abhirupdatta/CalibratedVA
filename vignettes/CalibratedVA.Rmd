---
title: "CalibratedVA"
author: "Jacob Fiksel and Abhirup Datta"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: bibliography.bib
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  message = FALSE,
  cache = TRUE
)
```

## Introduction

Many countries cannot conduct full autopsies for the majority of deaths due to either cultural or economic limitations [@abouzahr2015civil; @allotey2015let]. Rather than perform an invasive autopsy, an alternative method to determine the cause (or "etiology") of death (COD) is to conduct a *verbal autopsy* (VA), where relatives of the deceased individual are asked a set list of questions to obtain information about symptoms experienced by the deceased observed prior to death [@soleman2006verbal]. Medical experts can then
use these VA responses to determine the COD for an individual.

If we are interested in obtaining causes of death for a large amount of individuals in a
region or country, in order to determine optimal resource allocation, we need an efficient
way to scale the process of determining the COD from VA data. Several algorithms have
recently been proposed to automatically predict COD from VA records. These *computer coded* VA (CCVA) algorithms predict COD using the VA records as input. Examples include Tariff [@tariff; @tariff2], interVA [@interva], and InsilicoVA [@insilico]. These algorithms all require datasets with both VA symptom data and
a gold standard (GS) COD determined for each individual.


If we are interested in obtaining population cause specific mortality fraction (CSMF), we can 
train one of the above algorithms with GS COD data from our country of interest,
obtain individual predictions from VA data for our
country of interest, and then aggregate the predictions to the CSMF level. However,
there may be limited amounts of GS COD data for a new country. In addition,
algorithms trained on GS COD from other countries may not be as accurate.


The CalibratedVA package is to be used for exactly the situation above--
we take predictions from one or multiple algorithm(s) trained on a large 
non-local dataset, and use the local GS COD dataset to improve the
CSMF estimates.

## PHMRC Data

The Population Health Metrics Research Consortium (PHMRC) study contains GS COD data
for children, neonates and adults in 4 countries, making it a perfect dataset
to demonstrate the merits of `CalibratedVA`. In this vignette, we will use the `openVA` package to obtain PHMRC data and implement the Tariff and InSilicoVA algorithms. We will of course also have to load the `CalibratedVA` package.


```{r load_pkgs}
library(openVA)
library(CalibratedVA)
```

We will now load in the PHMRC child data and use the `ConvertData.phmrc` function
to convert the data into the appropriate structure for Tariff and InSilicoVA.

```{r convert_data}
child.raw <- read.csv(getPHMRC_url("child"))
child.clean <- ConvertData.phmrc(child.raw, phmrc.type = "child")$output
```

To demonstrate how to implement CalibratedVA, we will first treat Tanzania as our country of interest
for obtaining accurate CSMF estimates. We will split the PHMRC data from Tanzania into a hospital (calibration) and population (test) set, and use the rest of the PHMRC data as our gold standard (training) set. We will use a calibration set size of 100.

```{r split_data}
countries <- ifelse(child.raw$site %in% c("Dar", "Pemba"), "Tanzania", "Other")
tanzania.data <- child.clean[countries == "Tanzania",]
train.data <- child.clean[countries == "Other",]
set.seed(851745)
calibration.indices <- sample(nrow(tanzania.data), 100, replace = F)
calibration.data <- tanzania.data[calibration.indices,]
test.data <- tanzania.data[-calibration.indices,]
```

## Implementing Tariff and InSilicoVA

In this section, we will use our training data to build prediction models using
the Tariff and InSilicoVA algorithms. First we will implement Tariff. 
Note that the `data` argument is the data for which we want to obtain COD
predictions for, which is both the calibration data and our test data (we 
will use the calibration set for CalibratedVA later in the vignette). When evaluating
the performance of these algorithms, we will only do so on the predictions
for the test data.

```{r tariff_train}
set.seed(123)
tariff.train <- codeVA(data = rbind(calibration.data, test.data),
                     data.type = "customize", model = "Tariff",
                     data.train = train.data, causes.train = "Cause")
```

We will now implement InSilicoVA.

```{r insilico_train}
set.seed(123)
insilico.train <- codeVA(data = rbind(calibration.data, test.data),
                         data.type = "customize", model = "InSilicoVA",
                         data.train = train.data, causes.train = "Cause",
                         jump.scale = 0.05, Nsim=5000, auto.length = FALSE)
```


## Implementing CalibratedVA with Individual Algorithms

For simplicity, we will restrict ourselves to predicting the distribution for the
top 3 COD (from Tanzania), and treat all other COD as "other". Because "Other Defined Causes of Child Deaths" is
coded as cause 14, we will not include this cause in the Top 4. 

We will extract predictions for the test and calibration set from both algorithms
implemented above, and then change any prediction that is not in the top 3 COD 
to other.

```{r top_3_cod}
top.cod <- names(sort(table(tanzania.data$Cause), decreasing = TRUE))
top3.cod <- top.cod[top.cod != "14"][1:3]
change.cause <- function(cause) {
    cause <- as.character(cause)
    cause[!(cause %in% top3.cod)] <- "99"
    return(cause)
}
tariff.train.cod <- change.cause(getTopCOD(tariff.train)[,2])
insilico.train.cod <- change.cause(getTopCOD(insilico.train)[,2])
test.changedcod <- change.cause(test.data$Cause)
calibration.changedcod <- change.cause(calibration.data$Cause)
```

Finally, we will separate out the InSilicoVA and Tariff predictions for
the test and calibration sets.

```{r separate_cod}
tariff.train.cod.test <- tariff.train.cod[-(1:100)]
tariff.train.cod.calib <- tariff.train.cod[1:100]
insilico.train.cod.test <- insilico.train.cod[-(1:100)]
insilico.train.cod.calib <- insilico.train.cod[1:100]
```

We will now initiate hyper-parameter values for CalibratedVA. These can be changed of course,
but we have found these values work well. We will run 3  chains, obtaining 50,000 draws
for each chains. Note that the order of the causes in the `causes` vector, 
as this is the order in which CalibratedVA will present the distribution of
COD estimates.

```{r hyperparams}
causes <- as.character(sort(unique(test.changedcod)))
epsilon <- .001
alpha <- .001
beta <- .001
tau <- .1
tau.vec <- rep(tau, length(causes))
delta <- 1
gamma.init <- 1
ndraws <- 50E3
nchains <- 3
```

We will first run CalibratedVA using the Tariff predictions.

```{r tariff_calibva, cache = TRUE}
set.seed(123)
calibva.seeds <- sample(1e6, nchains, replace = F)
tariff.calibva <- lapply(1:nchains, function(i) {
    set.seed(calibva.seeds[i])
    calibva.sampler(test.cod = tariff.train.cod.test, calib.cod = tariff.train.cod.calib,
                   calib.truth = calibration.changedcod, causes = causes,
                   epsilon = epsilon, alpha=alpha, beta=beta,
                   tau.vec=tau.vec, delta=delta,
                   gamma.init=gamma.init, ndraws = ndraws)
})
```

And now using the InSilicoVA predictions.

```{r insilico_calibva, cache = TRUE}
set.seed(123)
calibva.seeds <- sample(1e6, nchains, replace = F)
insilico.calibva <- lapply(1:nchains, function(i) {
    set.seed(calibva.seeds[i])
    calibva.sampler(test.cod = insilico.train.cod.test, calib.cod = insilico.train.cod.calib,
                   calib.truth = calibration.changedcod, causes = causes,
                   epsilon = epsilon, alpha=alpha, beta=beta,
                   tau.vec=tau.vec, delta=delta,
                   gamma.init=gamma.init, ndraws = ndraws)
})
```

## Implementing Ensemble CalibratedVA

The previous section clearly reveals that REVAMP can use the output from any CCVA algorithm. Several CCVA algorithms have been implemented in publicly available software; in any particular analysis, the optimal CCVA is unknown. For example, in the above implentation, if our population (test) set had not already been labeled with the GS COD, we would not know whether it would be best to implement CalibratedVA with Tariff or InSilicoVA. In the code below, we show how to implement the Independent CalibratedVA Ensemble Model, which uses the predictions from multiple VA-based algorithms. We use output from the Tariff and InSilicoVA models built in the previous section.

```{r calibva_ensemble, cache = TRUE}
set.seed(123)
calibva.seeds <- sample(1e6, nchains, replace = F)
test.cod.mat <- matrix(c(tariff.train.cod.test,  insilico.train.cod.test), ncol = 2)
calib.cod.mat <- matrix(c(tariff.train.cod.calib,  insilico.train.cod.calib), ncol = 2)
ensemble.calibva <- lapply(1:nchains, function(i) {
    set.seed(calibva.seeds[i])
    calibva.ensemble.lite.sampler(test.cod.mat = test.cod.mat, calib.cod.mat = calib.cod.mat,
                                 calib.truth = calibration.changedcod, causes = causes,
                                 epsilon = epsilon, alpha=alpha, beta=beta,
                                 tau.vec=tau.vec, delta=delta,
                                 gamma.init=gamma.init, ndraws = ndraws)
})
```

## Obtaining CalibratedVA output

The `calibva.sampler` (or `calibva.ensemble.lite.sampler`) output is a list of length `ndraws`. Each element in this list is itself a list, with each element containing a posterior draw for each parameter. We can inspect what this looks like, from our first chain of the CalibratedVA with Tariff sampler.

```{r inspect_posterior}
tariff.calibva[[1]][[5000]]
```

The most important parameters are the $p_{i}$, which is the true CSMF for COD $i$.
The $i$th element in $p_{i}$ refers to the $i$th element in the `causes` input
of `calibva.sampler`.

We can extract these parameter estimates using the `calibvaCSMF` function and then plot the posterior densities versus the true CSMF in the test set. We will use a burn-in of 10,000 and thin the draws by 10.

```{r extract_csmf}
burnin <- 10E3
thin <- 10

tariff.calibva.csmf.list <- lapply(1:nchains, function(i) {
    calibvaCSMF(tariff.calibva[[i]], burnin = burnin, thin = thin)
})
tariff.calibva.csmf.df <- do.call(rbind, tariff.calibva.csmf.list)

insilico.calibva.csmf.list <- lapply(1:nchains, function(i) {
    calibvaCSMF(insilico.calibva[[i]], burnin = burnin, thin = thin)
})
insilico.calibva.csmf.df <- do.call(rbind, insilico.calibva.csmf.list)

ensemble.calibva.csmf.list <- lapply(1:nchains, function(i) {
    calibvaCSMF(ensemble.calibva[[i]], burnin = burnin, thin = thin)
})
ensemble.calibva.csmf.df <- do.call(rbind, ensemble.calibva.csmf.list)

```

We can plot the posterior distribution of CSMF estimates from our CalibratedVA with
Tariff sample. We will show the true CSMF in red, and the estimated CSMF
from just Tariff in blue.

```{r post_tariff_dens_plot, fig.width = 6, fig.height = 6}
library(ggplot2)
library(dplyr)

true.p <- prop.table(table(change.cause(tanzania.data$Cause)))
true.p <- data.frame(p = unname(as.vector(true.p)), cause = names(true.p))
tariff.p <- prop.table(table(tariff.train.cod.test))
tariff.p <- data.frame(p = unname(as.vector(tariff.p)), cause = names(tariff.p))
ggplot() +
    geom_density(data = tariff.calibva.csmf.df, aes(p)) +
    geom_vline(data = true.p, aes(xintercept = p), colour = 'red') +
    geom_vline(data = tariff.p, aes(xintercept = p), colour = 'blue') +
    facet_wrap(~cause, scales = "free_y") +
    xlim(0, 1)
```

## Comparing algorithm accuracy

A common metric for comparing CSMF predictions is CSMF Accuracy, which is defined as 

$$
CSMF_{acc} = 1 - \frac{\sum_{i=1}^{C} (CSMF_{i} - CSMF_{i}^{(true)})}{2(1 - \text{min}\{CSMF^{(true)}\})}
$$

where $CSMF_{i}$ and $CSMF_{i}^{(true)}$ are the estimated and true percentages, respectively, of the population for which the GS COD is cause $i$, $i=1, \ldots, C$.

To obtain estimates of the CSMFs, we will use the marginal posterior means from the 
posterior draws. We will first write functions to obtain the point predictions
from CalibratedVA, Tariff, and InSilicoVA.

```{r csmf_functions}
calibvaCSMFMeanEstimate <- function(calibva.csmf.df, causes) {
    csmf.init <- sapply(causes, function(c) {
        calibva.cause <- calibva.csmf.df[calibva.csmf.df$cause == c,]
        return(mean(calibva.cause$p))
    })
    return(csmf.init)
}

openVACSMF <- function(topcod, causes) {
    csmf <- sapply(causes, function(c) mean(topcod == c))
    return(csmf)
}
```

We will now obtain these CSMF estimates, using the causes defined in the code 
block where we set the CalibratedVA hyperparameter values.

```{r obtain_csmf}
tariff.calibva.csmf <- calibvaCSMFMeanEstimate(tariff.calibva.csmf.df, causes)
insilico.calibva.csmf <- calibvaCSMFMeanEstimate(insilico.calibva.csmf.df, causes)
ensemble.calibva.csmf <- calibvaCSMFMeanEstimate(ensemble.calibva.csmf.df, causes)
tariff.train.csmf <- openVACSMF(tariff.train.cod.test, causes)
insilico.train.csmf <- openVACSMF(insilico.train.cod.test, causes)
```

Finally, we will obtain and display the CSMF accuracy for these 5 methods.

```{r csmf_accuracy}
methods <- c("tariff_calibva",
             "insilico_calibva",
             "ensemble_calibva",
             "tariff_train",
             "insilico_train")
ptrue <- sapply(causes, function(c) mean(change.cause(tanzania.data$Cause) == c))
csmf.acc.df <- data.frame(csmf.acc = c(getCSMF_accuracy(tariff.calibva.csmf, ptrue),
                                       getCSMF_accuracy(insilico.calibva.csmf, ptrue),
                                       getCSMF_accuracy(ensemble.calibva.csmf, ptrue),
                                       getCSMF_accuracy(tariff.train.csmf, ptrue),
                                       getCSMF_accuracy(insilico.train.csmf, ptrue)),
                          method = methods)
csmf.acc.df
```

We see two interesting observations. First, all three CalibratedVA methods
substantially outperform Tariff and InSilicoVA in terms of CSMF accuracy. Second,
The CSMF accuracy of the ensemble method of CalibratedVA falls right in the middle of 
the CSMF accuracies of Tariff and CalibratedVA. This indicates that it is a useful method
to use, as it is always unknown whether Tariff or InSilicoVA will be the best performing algorithm.

## References
