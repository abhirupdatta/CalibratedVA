---
title: "ReVAMP"
author: "Jacob Fiksel and Abhirup Datta"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  message = FALSE
)
```

# Introduction

In many countries, it is infeasible to conduct full autopsies for each death, due to economic or infrastructural limitations. Consequently, national or sub-national statistics produced on cause-specific mortality numbers for many of these countries rely on data from verbal autopsy (VA) surveys. The VA data supplemented with physiciansâ€™ opinions or full autopsy reports for a smaller subset of the deaths are used to determine prediction rules that can ascertain a cause of death (COD) solely based on the VA report of an individual. Approaches to specify these rules include non-statistical algorithms including Tariff, InterVA and EAVA and more formal model based approaches like InsillicoVA that endows the prediction problem with a proper probabilistic framework allowing coherent statistical inference. To create the prediction algorithm, all of these approaches require a substantial training dataset, where both the VA reports and the true gold standard cause of deaths, either the full autopsies or the physicians' opinions are available.

The ReVAMP (Regularized Verbal Autopsy based Mortality Prediction) package is to be used
when a limited amount of gold standard cause of death data is available for a new country. 
Rather than train one of the existing algorithms on the extremely small gold standard data set, our algorithm uses a hierarchical Bayesian model in order to leverage the large amount of
PHMRC VA data available from other countries in informing CSMF estimates.

# Obtaining and splitting the PHMRC data

In this vignette, we will use the `openVA` package to obtain PHMRC data and implement 
the Tariff algorithm. We will of course also have to load the `ReVAMP` package.

```{r load_pkgs}
library(openVA)
library(ReVAMP)
```

We will now load in the PHMRC child data and use the `ConvertData.phmrc` function
to convert the data into the appropriate structure for Tariff.

```{r convert_data}
child.raw <- read.csv(getPHMRC_url("child"))
child.clean <- ConvertData.phmrc(child.raw, phmrc.type = "child")$output
```

For simplicity, we will restrict ourselves to the top 4 COD, and treat
all other COD as "other". Because "Other Defined Causes of Child Deaths" is
coded as cause 14, we will not include this cause in the Top 4.

```{r top_4_cod}
top.cod <- names(sort(table(child.clean$Cause), decreasing = TRUE))
top4.cod <- top.cod[top.cod != "14"][1:4]
child.clean$Cause[!(child.clean$Cause %in% top4.cod)] <- 99
```

We will now split the PHMRC data from India into a calibration and test set,
and use the rest of the PHMRC data as our training set. We will use a calibration
set size of 200.

```{r split_data}
set.seed(123)
countries <- ifelse(child.raw$site %in% c("AP", "UP"), "India", "Other")
india.data <- child.clean[countries == "India",]
train.data <- child.clean[countries == "Other",]
calibration.indices <- sample(nrow(india.data), 200, replace = F)
calibration.data <- india.data[calibration.indices,]
test.data <- india.data[-calibration.indices,]
```

# Implementing ReVAMP with Tariff

We will demonstrate how to use the ReVAMP method with the Tariff
training method for predicting COD from VA data. First we will train Tariff. 
Note that the `data` argument is the data for which we want to obtain COD
predictions for, which is both the calibration data and our test data.

```{r tariff_trainset}
set.seed(123)
tariff.fit <- codeVA(data = rbind(calibration.data, test.data),
                     data.type = "customize", model = "Tariff",
                     data.train = train.data, causes.train = "Cause")
```

We now need to extract three pieces of information for ReVAMP:

1. The individual COD predictions for the test set
2. The individual COD predictions for the calibration set
3. The gold-standard COD for the calibration set

Note that all of these must be character vectors

```{r extract_information_tariff}
pred.cod.tariff <- getTopCOD(tariff.fit)
pred.cod.tariff <- as.character(pred.cod.tariff[,2])
calib.cod.tariff <- pred.cod.tariff[1:nrow(calibration.data)]
test.cod.tariff <- pred.cod.tariff[-(1:nrow(calibration.data))]
calib.truth <- as.character(calibration.data$Cause)
```

We will now initiate hyper-parameter values for ReVAMP. These can be changed of course,
but we have found these values work well. We will set the number of draws
to 100,000. We recommend running multiple
chains to check for convergence, but we will not do this in the vignette for computational efficiency. This can be done by setting a new seed before running the algorithm.

```{r hyperparams}
causes <- as.character(sort(unique(test.data$Cause)))
epsilon <- .001
alpha <- .001
beta <- .001
tau <- .1
tau.vec <- rep(tau, length(causes))
delta <- 1
gamma.init <- 1
ndraws <- 50E3
```

We will run the `revamp.sampler` using the output from the Tariff model. We will only
run one chain of the sampler in order to quickly compile the vignette.

```{r tariff_revamp}
set.seed(1234)
tariff.revamp <- revamp.sampler(test.cod = test.cod.tariff, calib.cod = calib.cod.tariff,
                                calib.truth = calib.truth, causes = causes,
                                epsilon = epsilon, alpha=alpha, beta=beta,
                                tau.vec=tau.vec, delta=delta,
                                gamma.init=gamma.init, ndraws = ndraws)
```


# Obtaining ReVAMP output

The `revamp.sampler` output is a list of length `ndraws`. Each element in this list is itself a list, with each element containing a posterior draw for each parameter. We can inspect what this looks like.

```{r inspect_posterior}
tariff.revamp[[5000]]
```

The most important parameters are the $p_{i}$, which is the true CSMF for COD $i$.
The $i$th element in $p_{i}$ refers to the $i$th element in the `causes` input
of `revamp.sampler`.

We can extract these parameter estimates using the `revampCSMF` function and then plot the posterior densities versus
the true CSMF in the test set. We will use a burn-in of 2,000 and thin the draws by 5.

```{r post_dens_plot, fig.width = 6, fig.height = 6}
library(ggplot2)
library(dplyr)
burnin <- 20E3
thin <- 5

tariff.revamp.csmf <- revampCSMF(tariff.revamp, burnin = burnin, thin = thin)

true.p <- prop.table(table(test.data$Cause))
true.p <- data.frame(p = unname(as.vector(true.p)), cause = names(true.p))
ggplot() +
    geom_density(data = tariff.revamp.csmf, aes(p)) +
    geom_vline(data = true.p, aes(xintercept = p), colour = 'red') +
    facet_wrap(~cause, scales = "free_y")
```

We can also compare the CSMF Accuracy of the ReVAMP method to that of Tariff, where we define
CSMF Accuracy as 

$$
CSMF_{acc} = 1 - \frac{\sum_{i=1}^{C} (CSMF_{i} - CSMF_{i}^{(true)})}{2(1 - \text{min}\{CSMF^{(true)}\})}
$$


To obtain estimates of the CSMFs, we will use the marginal posterior modes from the 
posterior draws.

```{r}
getCSMFEstimate <- function(revamp.csmf.df, causes) {
    sapply(causes, function(c) {
        revamp.cause <- revamp.csmf.df[revamp.csmf.df$cause == c,]
        dens <- density(revamp.cause$p)
        return(dens$x[which.max(dens$y)])
    })
}

csmf.tariff <- sapply(causes, function(c) mean(test.cod.tariff == c))
csmf.tariff.revamp <- getCSMFEstimate(tariff.revamp.csmf, causes)
csmf.test <- sapply(causes, function(c) mean(test.data$Cause == c))
tariff.csmf.acc <- getCSMF_accuracy(csmf.tariff, csmf.test)
revamp.csmf.acc <- getCSMF_accuracy(csmf.tariff.revamp, csmf.test)

tariff.csmf.acc
revamp.csmf.acc
```

And we see that using `ReVAMP` leads to an improvement in CSMF accuracy.

# Ensemble ReVAMP

In practice, we may not want to rely on the COD estimated from just Tariff. Instead,
we may want to combine Tariff estimates with those of another algorithm such as
InsilicoVA. Furthermore, we can use the ReVAMP methodology to use both of these modeling
strategies.

We will first use InSilicoVA to get individual COD estimates for both our
calibration and test sets, as we did for Tariff.

```{r insilico_train}
set.seed(1234)
insilico.fit <- codeVA(data = rbind(calibration.data, test.data),
                         data.type = "customize", model = "InSilicoVA",
                         data.train = train.data, causes.train = "Cause",
                         jump.scale = 0.05, Nsim=5000, auto.length = FALSE)
pred.cod.insilico <- getTopCOD(insilico.fit)
pred.cod.insilico <- as.character(pred.cod.insilico[,2])
calib.cod.insilico <- pred.cod.insilico[1:nrow(calibration.data)]
test.cod.insilico <- pred.cod.insilico[-(1:nrow(calibration.data))]
```

We can quickly run ReVAMP with the InSilicoVA predictions to observe
differences between InSilicoVA and Tariff with ReVAMp

```{r}
set.seed(1234)
insilico.revamp <- revamp.sampler(test.cod = test.cod.insilico, calib.cod = calib.cod.insilico,
                                  calib.truth = calib.truth, causes = causes,
                                  epsilon = epsilon, alpha=alpha, beta=beta,
                                  tau.vec=tau.vec, delta=delta,
                                  gamma.init=gamma.init, ndraws = ndraws)
```

```{r plot_insilico_revamp}
insilico.revamp.csmf <- revampCSMF(insilico.revamp, burnin = burnin, thin = thin)

ggplot() +
    geom_density(data = insilico.revamp.csmf , aes(p)) +
    geom_vline(data = true.p, aes(xintercept = p), colour = 'red') +
    facet_wrap(~cause, scales = "free_y")
```

We can inspect the CSMFs again

```{r}
csmf.insilico <- sapply(causes, function(c) mean(test.cod.insilico == c))
csmf.revamp.insilico <- getCSMFEstimate(insilico.revamp.csmf, causes)
insilico.csmf.acc <- getCSMF_accuracy(csmf.insilico, csmf.test)
revamp.insilico.csmf.acc <- getCSMF_accuracy(csmf.revamp.insilico, csmf.test)
insilico.csmf.acc
revamp.insilico.csmf.acc
```

We now have to format the predictions from Tariff and InSilicoVA for the `revamp.ensemble.sampler` function.

```{r format_ensemble}
test.cod.mat <- matrix(c(test.cod.tariff, test.cod.insilico), ncol = 2)
calib.cod.mat <- matrix(c(calib.cod.tariff, calib.cod.insilico), ncol = 2)
```

And we now we can run the function using nearly identical arguments to that of the
`revamp.sampler` function. We will reduce the number of draws, since this is a more
computationally intensive procedure.

```{r revamp_ensemble}
set.seed(1234)
ensemble.revamp <- revamp.ensemble.sampler(test.cod.mat = test.cod.mat,
                                           calib.cod.mat = calib.cod.mat,
                                           calib.truth = calib.truth, causes = causes,
                                           epsilon = epsilon, alpha=alpha, beta=beta,
                                           tau.vec=tau.vec, delta=delta,
                                           gamma.init=gamma.init, ndraws = 10000)
```

And we can again plot the posterior density for the ensemble CSMF estimates.

```{r plot_ensemble_csmf}
burnin <- 2E3
thin <- 5

ensemble.revamp.csmf <- revampCSMF(ensemble.revamp, burnin = burnin, thin = thin)

ggplot() +
    geom_density(data = ensemble.revamp.csmf , aes(p)) +
    geom_vline(data = true.p, aes(xintercept = p), colour = 'red') +
    facet_wrap(~cause, scales = "free_y")
```

And finally we can get the CSMF accuracy for our ensemble method:

```{r csmf_accuracy_ensemble}
csmf.revamp.ensemble <- sapply(causes, function(c) mean(ensemble.revamp.csmf$p[ensemble.revamp.csmf$cause == c]))
revamp.ensemble.csmf.acc <- getCSMF_accuracy(csmf.revamp.ensemble, csmf.test)
revamp.ensemble.csmf.acc
```

Which appears to be a dramatic increase in accuracy from either of the two
individual methods + ReVAMP

# Individual predictions with ReVAMP

We will obtain individual predictions from all three ReVAMP methods using either the `revampIndPredictions`
function or the `revampEnsembleIndPredictions` function, based on whether we used ensemble calibration. These functions take in the posterior samples from either the `revamp.sampler` or `revamp.ensemble.sampler` function, 
as well as the COD predictions (either a vector for an individual algorith or a matrix for the ensemble method) for the test subjects. It also takes in the causes argument discussed previously, as well as
burn-in and thin arguments.

```{r obtain_indiv_cod}
tariff.revamp.ind.cod <- revampIndPredictions(tariff.revamp, test.cod = test.cod.tariff,
                                       causes = causes,burnin = 2000, thin = 5)$topCOD
insilico.revamp.ind.cod <- revampIndPredictions(insilico.revamp, test.cod = test.cod.insilico,
                                       causes = causes,burnin = 2000, thin = 5)$topCOD
ensemble.revamp.ind.cod <- revampEnsembleIndPredictions(ensemble.revamp, test.cod.mat = test.cod.mat,
                                                        causes = causes,burnin = 2000, thin = 5)$topCOD
```

We can now look at the chance-corrected concordance (CCC) metric for measuring how
well each algorithm performs in individual predictions. We define the CCC
for cause j as:

$$
CCC_{j} = \frac{\frac{\text{# correctly assigned to cause j}}{\text{# total number of death from cause j}} - \frac{1}{C}}{1 - \frac{1}{C}}
$$

We first have to write a custom function to estimate the CCC

```{r ccc_function}
ccc <- function(cod.est, cod.truth, causes) {
    C <- length(causes)
    ccc <- sapply(seq_along(causes), function(j) {
        cause.j <- causes[j]
        correct.assign <- sum(cod.est == cause.j & cod.truth == cause.j)
        total <- sum(cod.truth == cause.j)
        if(total == 0) {
            total <- 1
        }
        numerator <- (correct.assign / total) - (1 / C)
        denominator <- 1 - (1 / C)
        return(numerator / denominator)
    })
}
```

And now we will estimate the CCC for all 5 of the methods we have tried

```{r}
tariff.ccc <- ccc(test.cod.tariff, as.character(test.data$Cause), causes)
insilico.ccc <- ccc(test.cod.insilico, as.character(test.data$Cause), causes)
tariff.revamp.ccc <- ccc(tariff.revamp.ind.cod, as.character(test.data$Cause), causes)
insilico.revamp.ccc <- ccc(insilico.revamp.ind.cod, as.character(test.data$Cause), causes)
ensemble.revamp.ccc <- ccc(ensemble.revamp.ind.cod, as.character(test.data$Cause), causes)
```

We will now list the individual CCC along with the true CSMF

```{r}
true.p
tariff.ccc
insilico.ccc
tariff.revamp.ccc
insilico.revamp.ccc
ensemble.revamp.ccc
```

While we see that in this example, ReVAMP has as low CCC for causes with a low CSMF, it outperforms
Tariff quite significantly for the more common causes of death. It appears that InSilicoVA
performs quite well in this example, and is about on par with ReVAMP.


