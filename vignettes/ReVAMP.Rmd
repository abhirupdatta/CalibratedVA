---
title: "ReVAMP"
author: "Jacob Fiksel and Abhirup Datta"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  message = FALSE
)
```

# Introduction

In many countries, it is infeasible to conduct full autopsies for each death, due to economic or infrastructural limitations. Consequently, national or sub-national statistics produced on cause-specific mortality numbers for many of these countries rely on data from verbal autopsy (VA) surveys. The VA data supplemented with physiciansâ€™ opinions or full autopsy reports for a smaller subset of the deaths are used to determine prediction rules that can ascertain a cause of death (COD) solely based on the VA report of an individual. Approaches to specify these rules include non-statistical algorithms including Tariff, InterVA and EAVA and more formal model based approaches like InsillicoVA that endows the prediction problem with a proper probabilistic framework allowing coherent statistical inference. To create the prediction algorithm, all of these approaches require a substantial training dataset, where both the VA reports and the true gold standard cause of deaths, either the full autopsies or the physicians' opinions are available.

The ReVAMP (Regularized Verbal Autopsy based Mortality Prediction) package is to be used
when a limited amount of gold standard cause of death data is available for a new country. 
Rather than train one of the existing algorithms on the extremely small gold standard data set, our algorithm uses a hierarchical Bayesian model in order to leverage the large amount of
PHMRC VA data available from other countries in informing CSMF estimates.

# Obtaining and splitting the PHMRC data

In this vignette, we will use the `openVA` package to obtain PHMRC data and implement 
the Tariff algorithm. We will of course also have to load the `ReVAMP` package.

```{r load_pkgs}
library(openVA)
library(ReVAMP)
```

We will now load in the PHMRC child data and use the `ConvertData.phmrc` function
to convert the data into the appropriate structure for Tariff.

```{r convert_data}
child.raw <- read.csv(getPHMRC_url("child"))
child.clean <- ConvertData.phmrc(child.raw, phmrc.type = "child")$output
```

We will split the PHMRC data from Tanzania into a calibration and test set,
and use the rest of the PHMRC data as our training set. We will use a calibration
set size of 100.

```{r split_data}
countries <- ifelse(child.raw$site %in% c("Dar", "Pemba"), "Tanzania", "Other")
tanzania.data <- child.clean[countries == "Tanzania",]
train.data <- child.clean[countries == "Other",]
set.seed(851745)
calibration.indices <- sample(nrow(tanzania.data), 100, replace = F)
calibration.data <- tanzania.data[calibration.indices,]
test.data <- tanzania.data[-calibration.indices,]
```

# Implementing individual VA algorithms

In this section, we will use our training data to build prediction models using
the Tariff and InSilicoVA algorithms. First we will implement Tariff. 
Note that the `data` argument is the data for which we want to obtain COD
predictions for, which is both the calibration data and our test data (we 
will use the calibration set for ReVAMP later in the vignette). When evaluating
the performance of these algorithms, we will only do so on the predictions
for the test data.

```{r tariff_train}
set.seed(123)
tariff.train <- codeVA(data = rbind(calibration.data, test.data),
                     data.type = "customize", model = "Tariff",
                     data.train = train.data, causes.train = "Cause")
```

We will now implement InSilicoVA.

```{r insilico_train}
set.seed(123)
insilico.train <- codeVA(data = rbind(calibration.data, test.data),
                         data.type = "customize", model = "InSilicoVA",
                         data.train = train.data, causes.train = "Cause",
                         jump.scale = 0.05, Nsim=5000, auto.length = FALSE)
```


# Implementing ReVAMP with Individual Algorithms

For simplicity, we will restrict ourselves to predicting the distribution for the
top 3 COD (from Tanzania), and treat all other COD as "other". Because "Other Defined Causes of Child Deaths" is
coded as cause 14, we will not include this cause in the Top 4. 

We will extract predictions for the test and calibration set from both algorithms
implemented above, and then change any prediction that is not in the top 3 COD 
to other.

```{r top_3_cod}
top.cod <- names(sort(table(tanzania.data$Cause), decreasing = TRUE))
top3.cod <- top.cod[top.cod != "14"][1:3]
change.cause <- function(cause) {
    cause <- as.character(cause)
    cause[!(cause %in% top3.cod)] <- "99"
    return(cause)
}
tariff.train.cod <- change.cause(getTopCOD(tariff.train)[,2])
insilico.train.cod <- change.cause(getTopCOD(insilico.train)[,2])
test.changedcod <- change.cause(test.data$Cause)
calibration.changedcod <- change.cause(calibration.data$Cause)
```

Finally, we will separate out the InSilicoVA and Tariff predictions for
the test and calibration sets.

```{r separate_cod}
tariff.train.cod.test <- tariff.train.cod[-(1:100)]
tariff.train.cod.calib <- tariff.train.cod[1:100]
insilico.train.cod.test <- insilico.train.cod[-(1:100)]
insilico.train.cod.calib <- insilico.train.cod[1:100]
```

We will now initiate hyper-parameter values for ReVAMP. These can be changed of course,
but we have found these values work well. We will run 3  chains, obtaining 50,000 draws
for each chains. Note that the order of the causes in the `causes` vector, 
as this is the order in which ReVAMP will present the distribution of
COD estimates.

```{r hyperparams}
causes <- as.character(sort(unique(test.changedcod)))
epsilon <- .001
alpha <- .001
beta <- .001
tau <- .1
tau.vec <- rep(tau, length(causes))
delta <- 1
gamma.init <- 1
ndraws <- 50E3
nchains <- 3
```

We will first run ReVAMP using the Tariff predictions.

```{r tariff_revamp}
set.seed(123)
revamp.seeds <- sample(1e6, nchains, replace = F)
tariff.revamp <- lapply(1:nchains, function(i) {
    set.seed(revamp.seeds[i])
    revamp.sampler(test.cod = tariff.train.cod.test, calib.cod = tariff.train.cod.calib,
                   calib.truth = calibration.changedcod, causes = causes,
                   epsilon = epsilon, alpha=alpha, beta=beta,
                   tau.vec=tau.vec, delta=delta,
                   gamma.init=gamma.init, ndraws = ndraws)
})
```

And now using the InSilicoVA predictions.

```{r insilico_revamp}
set.seed(123)
revamp.seeds <- sample(1e6, nchains, replace = F)
insilico.revamp <- lapply(1:nchains, function(i) {
    set.seed(revamp.seeds[i])
    revamp.sampler(test.cod = insilico.train.cod.test, calib.cod = insilico.train.cod.calib,
                   calib.truth = calibration.changedcod, causes = causes,
                   epsilon = epsilon, alpha=alpha, beta=beta,
                   tau.vec=tau.vec, delta=delta,
                   gamma.init=gamma.init, ndraws = ndraws)
})
```

# Implementing Ensemble ReVAMP

It may be advantageous to use predictions from multiple VA algorithms in order
to inform ReVAMP predicted COD distributions. In this section, we will show
how to implement the ReVAMP ensemble sampler.

```{r revamp_ensemble}
set.seed(123)
revamp.seeds <- sample(1e6, nchains, replace = F)
test.cod.mat <- matrix(c(tariff.train.cod.test,  insilico.train.cod.test), ncol = 2)
calib.cod.mat <- matrix(c(tariff.train.cod.calib,  insilico.train.cod.calib), ncol = 2)
ensemble.revamp <- lapply(1:nchains, function(i) {
    set.seed(revamp.seeds[i])
    revamp.ensemble.lite.sampler(test.cod.mat = test.cod.mat, calib.cod.mat = calib.cod.mat,
                                 calib.truth = calibration.changedcod, causes = causes,
                                 epsilon = epsilon, alpha=alpha, beta=beta,
                                 tau.vec=tau.vec, delta=delta,
                                 gamma.init=gamma.init, ndraws = ndraws)
})
```

# Obtaining ReVAMP output

The `revamp.sampler` output is a list of length `ndraws`. Each element in this list is itself a list, with each element containing a posterior draw for each parameter. We can inspect what this looks like, from
our first chain of the ReVAMP with Tariff sampler.

```{r inspect_posterior}
tariff.revamp[[1]][[5000]]
```

The most important parameters are the $p_{i}$, which is the true CSMF for COD $i$.
The $i$th element in $p_{i}$ refers to the $i$th element in the `causes` input
of `revamp.sampler`.

We can extract these parameter estimates using the `revampCSMF` function and then plot the posterior densities versus the true CSMF in the test set. We will use a burn-in of 10,000 and thin the draws by 10.

```{r extract_csmf}
burnin <- 10E3
thin <- 10

tariff.revamp.csmf.list <- lapply(1:nchains, function(i) {
    revampCSMF(tariff.revamp[[i]], burnin = burnin, thin = thin)
})
tariff.revamp.csmf.df <- do.call(rbind, tariff.revamp.csmf.list)

insilico.revamp.csmf.list <- lapply(1:nchains, function(i) {
    revampCSMF(insilico.revamp[[i]], burnin = burnin, thin = thin)
})
insilico.revamp.csmf.df <- do.call(rbind, insilico.revamp.csmf.list)

ensemble.revamp.csmf.list <- lapply(1:nchains, function(i) {
    revampCSMF(ensemble.revamp[[i]], burnin = burnin, thin = thin)
})
ensemble.revamp.csmf.df <- do.call(rbind, ensemble.revamp.csmf.list)

```

We can plot the posterior distribution of CSMF estimates from our ReVAMP with
Tariff sample. We will show the true CSMF in red, and the estimated CSMF
from just Tariff in blue.

```{r post_tariff_dens_plot, fig.width = 6, fig.height = 6}
library(ggplot2)
library(dplyr)

true.p <- prop.table(table(change.cause(tanzania.data$Cause)))
true.p <- data.frame(p = unname(as.vector(true.p)), cause = names(true.p))
tariff.p <- prop.table(table(tariff.train.cod.test))
tariff.p <- data.frame(p = unname(as.vector(tariff.p)), cause = names(tariff.p))
ggplot() +
    geom_density(data = tariff.revamp.csmf.df, aes(p)) +
    geom_vline(data = true.p, aes(xintercept = p), colour = 'red') +
    geom_vline(data = tariff.p, aes(xintercept = p), colour = 'blue') +
    facet_wrap(~cause, scales = "free_y") +
    xlim(0, 1)
```

# Comparing algorithm accuracy

A common metric for comparing CSMF predictions is CSMF Accuracy, which is defined as 

$$
CSMF_{acc} = 1 - \frac{\sum_{i=1}^{C} (CSMF_{i} - CSMF_{i}^{(true)})}{2(1 - \text{min}\{CSMF^{(true)}\})}
$$


To obtain estimates of the CSMFs, we will use the marginal posterior means from the 
posterior draws. We will first write functions to obtain the point predictions
from ReVAMP, Tariff, and InSilicoVA.

```{r csmf_functions}
revampCSMFMeanEstimate <- function(revamp.csmf.df, causes) {
    csmf.init <- sapply(causes, function(c) {
        revamp.cause <- revamp.csmf.df[revamp.csmf.df$cause == c,]
        return(mean(revamp.cause$p))
    })
    return(csmf.init)
}

openVACSMF <- function(topcod, causes) {
    csmf <- sapply(causes, function(c) mean(topcod == c))
    return(csmf)
}
```

We will now obtain these CSMF estimates, using the causes defined in the code 
block where we set the ReVAMP hyperparameter values.

```{r obtain_csmf}
tariff.revamp.csmf <- revampCSMFMeanEstimate(tariff.revamp.csmf.df, causes)
insilico.revamp.csmf <- revampCSMFMeanEstimate(insilico.revamp.csmf.df, causes)
ensemble.revamp.csmf <- revampCSMFMeanEstimate(ensemble.revamp.csmf.df, causes)
tariff.train.csmf <- openVACSMF(tariff.train.cod.test, causes)
insilico.train.csmf <- openVACSMF(insilico.train.cod.test, causes)
```

Finally, we will obtain and display the CSMF accuracy for these 5 methods.

```{r csmf_accuracy}
methods <- c("tariff_revamp",
             "insilico_revamp",
             "ensemble_revamp",
             "tariff_train",
             "insilico_train")
ptrue <- sapply(causes, function(c) mean(change.cause(tanzania.data$Cause) == c))
csmf.acc.df <- data.frame(csmf.acc = c(getCSMF_accuracy(tariff.revamp.csmf, ptrue),
                                       getCSMF_accuracy(insilico.revamp.csmf, ptrue),
                                       getCSMF_accuracy(ensemble.revamp.csmf, ptrue),
                                       getCSMF_accuracy(tariff.train.csmf, ptrue),
                                       getCSMF_accuracy(insilico.train.csmf, ptrue)),
                          method = methods)
csmf.acc.df
```

We see two interesting observations. First, all three ReVAMP methods
substantially outperform Tariff and InSilicoVA in terms of CSMF accuracy. Second,
The CSMF accuracy of the ensemble method of ReVAMP falls right in the middle of 
the CSMF accuracies of Tariff and ReVAMP. This indicates that it is a useful method
to use, as it is always unknown whether Tariff or InSilicoVA will be the best performing algorithm.
