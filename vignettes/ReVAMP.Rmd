---
title: "ReVAMP"
author: "Jacob Fiksel and Abhirup Datta"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  message = FALSE
)
```

# Introduction

In many countries, it is infeasible to conduct full autopsies for each death, due to economic or infrastructural limitations. Consequently, national or sub-national statistics produced on cause-specific mortality numbers for many of these countries rely on data from verbal autopsy (VA) surveys. The VA data supplemented with physiciansâ€™ opinions or full autopsy reports for a smaller subset of the deaths are used to determine prediction rules that can ascertain a cause of death (COD) solely based on the VA report of an individual. Approaches to specify these rules include non-statistical algorithms including Tariff, InterVA and EAVA and more formal model based approaches like InsillicoVA that endows the prediction problem with a proper probabilistic framework allowing coherent statistical inference. To create the prediction algorithm, all of these approaches require a substantial training dataset, where both the VA reports and the true gold standard cause of deaths, either the full autopsies or the physicians' opinions are available.

The ReVAMP (Regularized Verbal Autopsy based Mortality Prediction) package is to be used
when a limited amount of gold standard cause of death data is available for a new country. 
Rather than train one of the existing algorithms on the extremely small gold standard data set, our algorithm uses a hierarchical Bayesian model in order to leverage the large amount of
PHMRC VA data available from other countries in informing CSMF estimates.

# Preparing the data

### Obtaining and splitting the PHMRC data

In this vignette, we will use the `openVA` package to obtain PHMRC data and implement 
the Tariff algorithm. We will of course also have to load the `ReVAMP` package.

```{r load_pkgs}
library(openVA)
library(ReVAMP)
```

We will now load in the PHMRC child data and use the `ConvertData.phmrc` function
to convert the data into the appropriate structure for Tariff.

```{r convert_data}
child.raw <- read.csv(getPHMRC_url("child"))
child.clean <- ConvertData.phmrc(child.raw, phmrc.type = "child")$output
```

For simplicity, we will restrict ourselves to the top 4 COD, and treat
all other COD as "other". Because "Other Defined Causes of Child Deaths" is
coded as cause 14, we will not include this cause in the Top 4.

```{r top_4_cod}
top.cod <- names(sort(table(child.clean$Cause), decreasing = TRUE))
top4.cod <- top.cod[top.cod != "14"][1:4]
child.clean$Cause[!(child.clean$Cause %in% top4.cod)] <- 99
```

We will now split the PHMRC data from India into a calibration and test set,
and use the rest of the PHMRC data as our training set. We will use a calibration
set size of 200.

```{r split_data}
set.seed(123)
countries <- ifelse(child.raw$site %in% c("AP", "UP"), "India", "Other")
india.data <- child.clean[countries == "India",]
train.data <- child.clean[countries == "Other",]
calibration.indices <- sample(nrow(india.data), 200, replace = F)
calibration.data <- india.data[calibration.indices,]
test.data <- india.data[-calibration.indices,]
```

### Implementing Tariff

We will first implement Tariff on the training dataset. However, any algorithm
which uses the symptoms to predict a COD for an individual can be used.

```{r tariff_trainset}
tariff.fit <- tariff(causes.train = "Cause",
                    symps.train = train.data,
                    symps.test = rbind(calibration.data, test.data))
```

### Formatting data for ReVAMP

We need two main inputs for ReVAMP. The first is a vector $v$ where $v_{i}$ is the
number of observations in the test (or test + calibration) set that the trained
(Tariff) model predicts to have died of cause $i$. The second is a matrix $T$ where 
$T_{i,j}$ is the number of records in the calibration set where the true COD
is $i$ and the predicted COD from the trained (Tariff) model is $j$. 

Note that $v$ should be of length $C$ and $T$ should be of dimension $C \times C$,
where $C$ is the total number of causes of death. Also, the $ith$ entry in $v$ should
correspond to the same COD as the $ith$ row (and column) in $T$. 

```{r format_for_revamp}
allcauses <- sort(unique(calibration.data$Cause))
ncauses <- length(allcauses)
all.predictions <- tariff.fit$causes.test[,2]
calibration.predictions <- all.predictions[1:nrow(calibration.data)]

v <- sapply(allcauses, function(c) sum(all.predictions == c))
names(v) <- allcauses
    
T.mat <- matrix(NA, nrow = ncauses, ncol = ncauses)
calib.truecod <- calibration.data$Cause
for(i in 1:ncauses){
    for(j in 1:ncauses){
        T.mat[i,j] <- sum(calib.truecod == allcauses[i] & calibration.predictions == allcauses[j])
    }
}
colnames(T.mat) <- rownames(T.mat) <- allcauses
```

# Implementing ReVAMP

We first will initiate hyper-parameter values. These can be changed of course,
but we have found these values work well. We will set the number of draws
to 10,000 for computational speed in creating the Vignette, but we recommend
using more (50,000 - 150,000). Further more, we recommend running multiple
chains to check for convergence. This can be done by setting a new seed
before running the algorithm.

```{r hyperparams}
epsilon <- .001
alpha <- .001
beta <- .001
tau <- .1
tau.vec <- rep(tau, ncauses)
delta <- 1
gamma.init <- 1
ndraws <- 10E3
```

And now we will run the ReVAMP algorithm

```{r gibbs.sampler}
set.seed(123)
posterior <- gibbs.sampler(v = v, T.mat = T.mat, epsilon = epsilon,
                               alpha=alpha, beta=beta, tau.vec=tau.vec, delta=delta,
                               gamma.init=gamma.init, ndraws = ndraws)
```

The output is a list of length `ndraws`, with each element containing a posterior 
draw for each parameter. We can inspect what this looks like.

```{r inspect_posterior}
posterior[[5000]]
```

The most important parameters are the $p_{i}$, which is the true CSMF for COD $i$. 
We can extract these parameter estimates and then plot the posterior densities versus
the true CSMF in the test set. We will use a burn-in of 1,000 and thin the draws by 5.

```{r post_dens_plot, fig.width = 6, fig.height = 6}
library(ggplot2)
library(dplyr)
burnin <- 1E3
thin <- 5


post.p <- lapply(seq(burnin, ndraws, by = thin), function(i) {
    draw.p <- posterior[[i]]$p
    return(data.frame(p = draw.p, cause = as.character(allcauses), draw = i))
})
post.p <- do.call(rbind, post.p)
true.p <- prop.table(table(test.data$Cause))
true.p <- data.frame(p = unname(as.vector(true.p)), cause = names(true.p))
ggplot() +
    geom_density(data = post.p, aes(p)) +
    geom_vline(data = true.p, aes(xintercept = p), colour = 'red') +
    facet_wrap(~cause)
```